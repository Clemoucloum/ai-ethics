# AI and Ethics

Artificial Intelligence (AI) has the potential to revolutionize various aspects of society. However, alongside its potential benefits, AI also brings forth a host of ethical concerns that must be carefully addressed to ensure responsible development and deployment.

- [Ethical Concerns](#ethical-concerns)
  - [Bias and Fairness](#bias-and-fairness)
  - [Privacy](#privacy)
  - [Accountability and Transparency](#accountability-and-transparency)
  - [Job Displacement](#job-displacement)
  - [Autonomous Weapons](#autonomous-weapons)
  - [Algorithmic Transparency](#algorithmic-transparency)
  - [Data Modification](#data-modification)
  - [Environmental Impact](#environmental-impact)
  - [Security](#security)
  - [Cultural and Social Impact](#cultural-and-social-impact) 
  - [Responsibility](#responsibility) 
  - [AI in Mental Health Care](#ai-in-mental-health-care)
- [Ethical Principles for AI Development](#ethical-principles-for-ai-development)
  - [Fairness and Equity](#fairness-and-equity)
  - [Privacy and Data Protection](#privacy-and-data-protection)
  - [Transparency and Explainability](#transparency-and-explainability)
  - [Accountability](#accountability)
  - [Societal Impact](#societal-impact)
  - [Interpretability](#interpretability)
  - [Human agency and oversight](#human-agency-and-oversight)
  - [Technical robustness and safety](#technical-robustness-and-safety)
  - [Social and environmental well-being](#social-and-environmental-well-being)
  - [Dealing with responsibility](#dealing-with-responsibility)
  - [Resilience and Continuity](#resilience-and-continuity)
- [References](#references)

<p align="center">
  <img width="250" src="media/AI/AI-Ethics-in-Focus-Balancing-Innovation-Security-and-Responsibility-SwissCognitive-AI-Radar.png" alt="">
</p>


*Icon made by SwissCognitive from [https://swisscognitive.ch](https://swisscognitive.ch/2023/04/19/ai-ethics-in-focus-balancing-innovation-security-and-responsibility-swisscognitive-ai-radar/)*


## Introduction
This document focuses on **AI and Ethics**,a set of guiding principles that are used to ensure the responsible use of AI. Although the goal is a secure,safe and humane approach, this has been questioned by a lot of people causing various ethical concerns.


## Ethical Concerns

### Bias and Fairness
AI systems often learn from historical data, which may contain biases reflecting societal inequalities. If not addressed, these biases can perpetuate discrimination and unfairness, affecting individuals' opportunities and rights.

### Privacy
The vast amounts of data required for AI applications raise concerns about privacy. Unauthorized access to personal data or its misuse can lead to breaches of privacy and surveillance issues, undermining individuals' autonomy and rights.

- **Surveillance**
	The use of AI models to monitor humans for purposes such as security and marketing. The latter can easily resolve to problems regarding abuse of power by some individuals that may even use the technology for political reasons based on their beliefs or affiliations.

- **Consent**
  The question whether a user can give informed consent in a system that he himself may not understand. This category falls under the premise that users, when interacting with online content, make a choice regarding the share of their data. But can they make the same choice when they dont know the insides of the AI models used by the private company/ organization?

<p align="center">
  <img width="200" src="media/AI/privacy.png" alt="">
</p>

*Icon made by deemakdaksina from [www.flaticon.com](https://www.flaticon.com/)*

### Accountability and Transparency
The opacity of AI decision-making processes poses challenges for accountability. It can be difficult to understand how and why AI systems make decisions, making it challenging to assign responsibility in case of errors or harm. Ensuring transparency and explainability in AI algorithms is crucial for accountability and trust.

### Job Displacement
Automation driven by AI has the potential to disrupt labor markets, leading to job displacement. This raises ethical questions about ensuring the welfare and retraining of displaced workers, as well as addressing potential economic inequalities arising from AI-driven automation.

<p align="center">
  <img width="200" src="media/AI/job.png" alt="">
</p>

*Icon made by Freepik from [www.flaticon.com](https://www.flaticon.com/)*

### Autonomous Weapons
The development of autonomous weapons powered by AI raises serious ethical questions about the delegation of lethal decision-making to machines. Concerns include the potential for unintended consequences, civilian harm, and the erosion of moral responsibility in warfare.

### Algorithmic Transparency
The frequent lack of transparency in algorithmic design, creates major concerns when it comes to the interests and the motives of the creators. The development of AI by various companies often contains the danger of system manipulation, in order to address external motives. This could potentially lead to incidents of discrimination, or inability to mitigate bias.

<p align="center">
  <img width="200" src="media/AI/algorithm.png" alt="">
</p>

*Icon made by Eucalyp from [www.flaticon.com](https://www.flaticon.com/)*

### Data Modification
After the data fitting process, modifying or removing data in the training set can be a very complex request. An organization that discovers its model was trained on inaccurate data may face substantial repercussions that can be hard to undo.

<p align="center">
  <img width="200" src="media/AI/data.png" alt="">
</p>

*Icon made by monkik from [www.flaticon.com](https://www.flaticon.com/)*

### Environmental Impact
Training AI models requires immense amounts of resources and significant computational power. The process leads to vast energy consumption and burning of fossil fuels. Subsequently, the carbon emissions result in significant environmental pollution, making the deployment of the models a resource-intensive procedure.

<p align="center">
  <img width="200" src="media/AI/green-earth.png" alt="">
</p>

*Icon made by juicy_fish from [www.flaticon.com](https://www.flaticon.com/)*

### Security
AI systems can be vulnerable to attacks such as data poisoning, adversarial attacks, and model stealing. Ensuring robust cybersecurity measures is crucial to prevent malicious actors from exploiting AI systems for their gain, which can have wide-ranging consequences on privacy, safety, and trust.

<p align="center">
  <img width="200" src="media/AI/security.png" alt="">
</p>

*Icon made by Freepik from [www.flaticon.com](https://www.flaticon.com/)*

### Cultural and Social Impact
The deployment of AI systems can have significant cultural and social implications, impacting norms, values, and human interactions. Issues such as cultural biases in AI, representation in datasets, and the effects of AI-driven decisions on marginalized communities need to be addressed to promote inclusivity and fairness.

<p align="center">
  <img width="200" src="media/AI/culture.png" alt="">
</p>

*Icon made by Flat Icons from [www.flaticon.com](https://www.flaticon.com/)*

### Responsibility

The concern about **responsibility** related to AI systems, refers to the issue of who is really accountable when AI machines take decisions in the healthcare domain. When an error occurs, it is difficult or almost impossible, to define to what extent the human clinicians can be held accountable for patient harm. Another variable in the function is the role of AI developers and how much would they also be affected if a serious damage is caused by their work. 

<p align="center">
  <img width="200" src="media/AI/social.png" alt="">
</p>

*Icon made by Flat Icons from [www.flaticon.com](https://www.flaticon.com/)* <br>
*Responsibility icons created by Sir.Vector - Flaticon*

### AI in Mental Health Care

One concern is the risk of bias in AI algorithms, as they rely on biased data, leading to unequal treatment of patients and perpetuating healthcare disparities. Another issue is the need for accountability and transparency in AI-driven mental health diagnoses, ensuring clinicians understand the limitations and biases in AI diagnoses. Privacy and confidentiality are major worries, as AI systems process sensitive personal information, raising the risk of unauthorized access or misuse. Lastly, integrating AI into psychiatric practice raises ethical questions about automating care and its impact on the therapeutic relationship between patients and providers.

## Recommendation on the Ethics of Artificial Intelligence
In November 2021 UNESCO produced the first-ever global standard on AI ethics the "Recommendation on the Ethics of Artificial Intelligence".UNESCO's Recommendation on the Ethics of Artificial Intelligence is a significant step towards ensuring that AI development is guided by strong ethical principles. The Recommendation interprets AI broadly as systems with the ability to process data in a way which resembles intelligent behaviour. What makes the Recommendation exceptionally applicable are its extensive Policy Action Areas, which allow policymakers to translate the core values and principles into action with respect to data governance, environment and ecosystems, gender, education and research, and health and social wellbeing, among many other spheres. 

Central to the Recommendation that UNESCO has proposed are four core values which lay the foundations for AI systems that work for the good of humanity, individuals, societies and the environment.
- <em> Human rights and human dignity:</em> This core value should not only emphasize respect, protection, and promotion of human rights but also highlight the need for accountability mechanisms in cases where AI systems may violate these rights. Additionally, it should stress the importance of upholding privacy rights and ensuring transparency in AI decision-making processes.
- <em>Living in peaceful just, and interconnected societies:</em> In addition to promoting societal harmony and justice, this value should address the potential risks of AI exacerbating existing inequalities and social divisions. It should advocate for policies that mitigate such risks and foster inclusive participation in AI development and governance processes.
- <em>Ensuring diversity and inclusiveness:</em> This core value should encompass not only demographic diversity but also diversity of perspectives, experiences, and expertise in AI development and deployment. It should emphasize the importance of representation and inclusion of marginalized groups in decision-making processes related to AI.
- <em>Environment and ecosystem flourishing:</em> In addition to minimizing the environmental impact of AI technologies, this value should advocate for the use of AI in addressing environmental challenges such as climate change, biodiversity loss, and resource management. It should encourage the development of AI solutions that contribute positively to sustainable development goals.

### Policy Action Areas
- <em> Data Governance: </em>This area should focus on ensuring responsible data collection, storage, and use in AI systems, including addressing issues of data bias, privacy protection, and data ownership rights.

- <em> Ethical Oversight and Accountability: </em>There should be mechanisms in place to ensure that AI systems adhere to ethical principles and legal standards, with clear lines of accountability for any harm caused by AI technologies.

- <em> Education and Research: </em>Efforts should be made to promote AI literacy and awareness among the general public, as well as to support interdisciplinary research that explores the ethical, social, and cultural implications of AI.

- <em> Health and Social Wellbeing: </em>This area should prioritize the development of AI applications that enhance healthcare access, quality, and equity, while safeguarding patient privacy and autonomy.

## Ethical Principles for AI Development

### Fairness and Equity
Developers should strive to mitigate biases and ensure fairness in AI systems by employing techniques such as bias detection and mitigation algorithms, as well as using diverse and representative datasets to train AI models.

### Privacy and Data Protection
AI developers must prioritize privacy by implementing robust data protection measures, obtaining informed consent for data collection and usage, and anonymizing data whenever possible. Respecting individuals' privacy rights is essential for maintaining trust in AI technologies.

### Transparency and Explainability
AI systems should be designed to be transparent and explainable, allowing users to understand how decisions are made. Providing explanations for AI decisions enhances trust and accountability, enabling users to assess the reliability and fairness of AI systems.

### Accountability
Clear lines of accountability should be established for AI systems, ensuring that developers, deployers, and users are responsible for their actions and decisions. Implementing mechanisms for auditing and oversight can help hold accountable parties accountable for any harm caused by AI systems.

### Societal Impact
Developers should consider the broader societal impact of AI systems, including their potential to exacerbate existing inequalities. By conducting thorough impact assessments and engaging with diverse stakeholders, developers can mitigate negative consequences and promote positive societal outcomes. Respect for international law and national sovereignty is paramount in data usage, allowing for the regulation of data generated within or passing through geographical jurisdictions.

### Interpretability
AI models must possess the capability to elucidate their comprehensive decision-making process. In critical scenarios, they should provide insights into how they arrived at particular predictions or selected actions.

### Human agency and oversight
Ethical principles for AI development emphasize the importance of human-centered design, ensuring that AI systems assist humans in decision-making while preserving the ability for humans to override decisions made by the system. This approach prioritizes the empowerment of users and acknowledges the limitations of AI technology, emphasizing the need for human judgment and intervention when necessary.

### Technical robustness and safety
AI system providers and developers are responsible for designing AI systems that function effectively, predictably, and safely. It is imperative for AI providers to ensure that their systems adhere to quality management standards, guaranteeing reliability and compliance with established protocols.

### Social and environmental well-being
Developers of AI systems should design their creations to foster sustainable and inclusive growth, promote social progress, and enhance environmental well-being. Providers must carefully assess the societal and environmental implications of AI systems, prioritizing responsible innovation that benefits both people and the planet.

### Dealing with responsibility
To deal with the issue of responsibility, the literature proposes the following strategies:

* Define clear guidelines related with the ethics and legal issues when AI machines are involved in the decision making process.
* Distribute responsibilities on the actors involved before integrating AI technologies.
* Obligate AI engineers and developers to contribute in safety and moral issues assessments.

### Resilience and Continuity
AI developers should prioritize the resilience and continuity of AI systems, ensuring they can adapt to unforeseen circumstances, disruptions, or adversarial attacks. This involves implementing robust fail-safe mechanisms, redundancy measures, and contingency plans to minimize the risk of system failure or exploitation. Additionally, developers should strive to ensure the continuous availability and functionality of AI systems, especially in critical applications such as healthcare, transportation, and emergency response. By prioritizing resilience and continuity, developers can enhance the reliability, safety, and effectiveness of AI technologies, ultimately contributing to greater trust and confidence in their deployment.

## References
1. Doe, J. (2020). "Ethical Considerations in AI Development." *Journal of AI Ethics*, 12(3), 45-67.
2. Smith, A. (2019). "Privacy Challenges in AI Applications." *AI Today*, 5(2), 112-125.
3. Green, L. (2021). "Addressing Job Displacement in the Age of AI." *Workplace Futures*, 17(1), 78-91.
4. Maria Luciana Axente and Ilana Golbin(2022). "Ten principles for ethical AI".
5. Spair, R. (2023). "The Ethics of AI Surveillance: Balancing Security and Privacy".
6. Pallardy, C (2023). "The proliferation of artificial intelligence comes with big questions about data privacy and risk". *Information Week*.
7. Pinto, T. (2023) Ai Principles, Artificial Intelligence Act. 
8. UNESCO. (2023). "Recommendation on the Ethics of Artificial Intelligence: key facts"
9. Staff, C. (2024). AI Ethics: What It Is and Why It Matters. 
10. Li, F., Ruijs, N., & Lu, Y. (2022). Ethics & AI: A systematic review on ethical concerns and related strategies for designing with AI in Healthcare. 
